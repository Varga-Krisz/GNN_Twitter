{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "TODO: Leírást gyártani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -q\n",
    "\n",
    "# pip didn't find pyg-lib for some reason\n",
    "#!pip install pyg-lib>=0.4 torch-scatter>=2.1 torch-sparse>=0.6 torch-cluster>=1.6 torch-spline_conv>=1.2 -f https://data.pyg.org/whl/torch-2.5.0+cu121.html --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0 with PyTorch version 2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Torch\n",
    "import torch\n",
    "\n",
    "# Graph\n",
    "import networkx as nx\n",
    "import torch_geometric as pyg\t# This import doesn't work\n",
    "import torch_geometric.nn as gnn\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.sampler import NegativeSampling\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "from model import *\n",
    "\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Default device breaks node and edge sampling\n",
    "#torch.set_default_device(DEVICE)\n",
    "\n",
    "print(f\"Training on {DEVICE} with PyTorch version {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "Loading, creating and splitting the data into dataloaders, defining train and test functions, import node2vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Bag_of_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'claychristensen': 1, 'coachella': 1, 'gabrie...</td>\n",
       "      <td>[tensor(31517), tensor(86), tensor(115673), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'brainpicker': 1, 'ev': 1, 'eventbrite': 1, '...</td>\n",
       "      <td>[tensor(3462), tensor(11073), tensor(24296), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'amyquispe': 1, 'baratunde': 1, 'busterbenson...</td>\n",
       "      <td>[tensor(70048), tensor(6685), tensor(24196), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'aaronsw': 1, 'abdur': 1, 'amac': 1, 'dustin'...</td>\n",
       "      <td>[tensor(24104), tensor(51836), tensor(25369), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{'al3x': 1, 'alexandrak': 1, 'allspaw': 1, 'av...</td>\n",
       "      <td>[tensor(25362), tensor(25367), tensor(25368), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Features  \\\n",
       "12  {'claychristensen': 1, 'coachella': 1, 'gabrie...   \n",
       "13  {'brainpicker': 1, 'ev': 1, 'eventbrite': 1, '...   \n",
       "17  {'amyquispe': 1, 'baratunde': 1, 'busterbenson...   \n",
       "20  {'aaronsw': 1, 'abdur': 1, 'amac': 1, 'dustin'...   \n",
       "47  {'al3x': 1, 'alexandrak': 1, 'allspaw': 1, 'av...   \n",
       "\n",
       "                                         Bag_of_Words  \n",
       "12  [tensor(31517), tensor(86), tensor(115673), te...  \n",
       "13  [tensor(3462), tensor(11073), tensor(24296), t...  \n",
       "17  [tensor(70048), tensor(6685), tensor(24196), t...  \n",
       "20  [tensor(24104), tensor(51836), tensor(25369), ...  \n",
       "47  [tensor(25362), tensor(25367), tensor(25368), ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load files created previously\n",
    "\n",
    "# Number of different feature names for the embedding size\n",
    "emb_size = 155522\n",
    "\n",
    "allfeats = pd.read_pickle(\"feature_bow.pkl\")\n",
    "allfeats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge list:\n",
      "            0          1\n",
      "0  214328887   34428380\n",
      "1   17116707   28465635\n",
      "2  380580781   18996905\n",
      "3  221036078  153460275\n",
      "4  107830991   17868918\n",
      "Complete graph nodes and edges:  81306 1768149\n",
      "Restricted graph nodes and edges:  70923 1655299\n",
      "Features of node index 12:\n",
      " {'BoW': tensor([ 31517,     86, 115673,   6741,   6741,  25306,   7622,  25768,  13811,\n",
      "        115629,   7120,   1681,  45262,  24086,   8859,   7310,  45288,  45228,\n",
      "         25336,  25336,  31027,   2976,   2976,  19157,  88730,  24332,  38647,\n",
      "         25698,  51775,  59974,  60065,  60010,  60015,  39992,   3173,   3122,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0], device='cuda:0')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 1655299], BoW=[70923, 195], num_nodes=70923)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create graph: from pandas to NetworkX to torch_geometric data object\n",
    "# Complete edge list\n",
    "edge_list = pd.read_csv(\"./Data/twitter_combined.txt\", sep=\" \", header=None)\n",
    "print(\"Edge list:\\n\", edge_list.head())\n",
    "\n",
    "# Complete graph\n",
    "G = nx.from_pandas_edgelist(edge_list, 0, 1, create_using=nx.DiGraph)\n",
    "print(\"Complete graph nodes and edges: \", G.number_of_nodes(), G.number_of_edges())\n",
    "\n",
    "# Restrict to nonzero feature nodes\n",
    "G = G.subgraph(allfeats.index)\n",
    "print(\"Restricted graph nodes and edges: \", G.number_of_nodes(), G.number_of_edges())\n",
    "\n",
    "# Give each node its it's bag of words as attribute\n",
    "nx.set_node_attributes(G, {idx: allfeats.Bag_of_Words[idx].to(DEVICE) for idx in allfeats.index}, \"BoW\")\n",
    "\n",
    "# Example\n",
    "print(\"Features of node index 12:\\n\", G.nodes[12])\n",
    "\n",
    "# Create the graph with a bag of words as the only node attribute\n",
    "graph = from_networkx(G)\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data: Apply train-val-test masks and create dataloaders\n",
    "\n",
    "transform = RandomLinkSplit(num_val=0.1, num_test=0.1)\n",
    "train_data, val_data, test_data = transform(graph)\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[20, 20],\n",
    "    neg_sampling=NegativeSampling(\"binary\"),\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data=val_data,\n",
    "    num_neighbors=[20, 20],\n",
    "    neg_sampling=NegativeSampling(\"binary\"),\n",
    "    batch_size=2048,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_loader = LinkNeighborLoader(\n",
    "    data=test_data,\n",
    "    num_neighbors=[20, 20],\n",
    "    neg_sampling=NegativeSampling(\"binary\"),\n",
    "    batch_size=2048,\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krisztián\\AppData\\Local\\Temp\\ipykernel_8128\\1831015820.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\"node2vec_trained.pt\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load node2vec embedding\n",
    "state = torch.load(\"node2vec_trained.pt\")\n",
    "n2v = gnn.Node2Vec(train_data.edge_index, 20, 10, 10).to(DEVICE)\n",
    "n2v.load_state_dict(state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline models\n",
    "\n",
    "### Not using the graph structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding + dot product\n",
    "\n",
    "**Theory:** People tend to follow people similar to them (i.e. form echo chambers)\n",
    "\n",
    "**Problem:** Symmetric, which is not good for directed edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='647'\n",
       "            max='647',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            647\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss: 1.1412, - accuracy: 0.1504\n",
      "Epoch 1: Valid loss: 0.8563 - accuracy: 0.1745\n",
      "Epoch 2: Train loss: 0.7814, - accuracy: 0.1932\n",
      "Epoch 2: Valid loss: 0.7141 - accuracy: 0.2066\n",
      "Epoch 3: Train loss: 0.6839, - accuracy: 0.2180\n",
      "Epoch 3: Valid loss: 0.6516 - accuracy: 0.2236\n",
      "Epoch 4: Train loss: 0.6368, - accuracy: 0.2297\n",
      "Epoch 4: Valid loss: 0.6203 - accuracy: 0.2305\n",
      "Epoch 5: Train loss: 0.6125, - accuracy: 0.2350\n",
      "Epoch 5: Valid loss: 0.6006 - accuracy: 0.2344\n",
      "Best val_acc: 0.23436670515412225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.1412242747716594,\n",
       "  0.7813725444780435,\n",
       "  0.6838626762998896,\n",
       "  0.6368485486949614,\n",
       "  0.6124703146206356],\n",
       " [0.15035291914387186,\n",
       "  0.19324692408708083,\n",
       "  0.21800110402864736,\n",
       "  0.22972555599773758,\n",
       "  0.23498403991418482],\n",
       " [0.8563484172732605,\n",
       "  0.7140930204708388,\n",
       "  0.6515710797892104,\n",
       "  0.620263319019188,\n",
       "  0.6005873164216738],\n",
       " [0.17446031349278568,\n",
       "  0.20659230457295916,\n",
       "  0.22363489727323047,\n",
       "  0.2304622043872679,\n",
       "  0.23436670515412225])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr, emb_dim = 0.001, 20\n",
    "model = DotProduct(emb_size, emb_dim).to(DEVICE)\n",
    "\n",
    "train_model(model=model, train_loader=train_loader, val_loader=val_loader, optimizer=\"Adam\", lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two fully connected layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='647'\n",
       "            max='647',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            647\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss: 0.6757, - accuracy: 0.4889\n",
      "Epoch 1: Valid loss: 0.6557 - accuracy: 0.4529\n",
      "Epoch 2: Train loss: 0.6424, - accuracy: 0.4192\n",
      "Epoch 2: Valid loss: 0.6290 - accuracy: 0.4111\n",
      "Epoch 3: Train loss: 0.6248, - accuracy: 0.4511\n",
      "Epoch 3: Valid loss: 0.6165 - accuracy: 0.4701\n",
      "Epoch 4: Train loss: 0.6170, - accuracy: 0.4794\n",
      "Epoch 4: Valid loss: 0.6107 - accuracy: 0.4872\n",
      "Epoch 5: Train loss: 0.6128, - accuracy: 0.4873\n",
      "Epoch 5: Valid loss: 0.6068 - accuracy: 0.4929\n",
      "Best val_acc: 0.49287893970961477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6757211400515514,\n",
       "  0.6423971508348928,\n",
       "  0.6247718452117542,\n",
       "  0.6170047130982695,\n",
       "  0.612798991490737],\n",
       " [0.48888117797289166,\n",
       "  0.41915972998872564,\n",
       "  0.4510776361704554,\n",
       "  0.47943085888444775,\n",
       "  0.4872640252038715],\n",
       " [0.6557093546416328,\n",
       "  0.6289802695720973,\n",
       "  0.616530851566073,\n",
       "  0.6106971181710316,\n",
       "  0.606817088963628],\n",
       " [0.45288659692608824,\n",
       "  0.4111423071782251,\n",
       "  0.4701236406364098,\n",
       "  0.4872213592540935,\n",
       "  0.49287893970961477])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr, emb_dim, hidden_dim = 0.1, 20, 256\n",
    "model = FCN(emb_size, emb_dim, hidden_dim).to(DEVICE)\n",
    "\n",
    "train_model(model=model, train_loader=train_loader, val_loader=val_loader, optimizer=\"SGD\", lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic GNN model\n",
    "\n",
    "Two CGN layers with reverse message passing, because the people we follow influence us.<br>\n",
    "(The reverse is also true, but to a lesser degree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='47'\n",
       "            max='1294',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            47\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m lr, emb_dim, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m256\u001b[39m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m GCN(emb_size, emb_dim, hidden, n2v)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAdam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Krisztián\\Documents\\Homework\\Mélytanulás\\Nagyházi\\model.py:203\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, numEpoch, optimizer, lr)\u001b[0m\n\u001b[0;32m    199\u001b[0m bar \u001b[38;5;241m=\u001b[39m display(progress(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_loader)), display_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(numEpoch):\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m     t_loss, t_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m     t_losses\u001b[38;5;241m.\u001b[39mappend(t_loss)\n\u001b[0;32m    205\u001b[0m     t_accs\u001b[38;5;241m.\u001b[39mappend(t_acc)\n",
      "File \u001b[1;32mc:\\Users\\Krisztián\\Documents\\Homework\\Mélytanulás\\Nagyházi\\model.py:44\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch, model, dataloader, optimizer, criterion, bar)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     43\u001b[0m \toptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 44\u001b[0m \toutputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \tloss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch\u001b[38;5;241m.\u001b[39medge_label\u001b[38;5;241m.\u001b[39mto(DEVICE))\n\u001b[0;32m     46\u001b[0m \tloss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Krisztián\\Documents\\Homework\\Mélytanulás\\Nagyházi\\Twitter_GNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Krisztián\\Documents\\Homework\\Mélytanulás\\Nagyházi\\Twitter_GNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Krisztián\\Documents\\Homework\\Mélytanulás\\Nagyházi\\model.py:175\u001b[0m, in \u001b[0;36mGCN.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    172\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlin(x))\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# cuda dies here...\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlin(out)), edge_index)\n\u001b[0;32m    178\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlin(out)))\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[1;32mc:\\Users\\Krisztián\\Documents\\Homework\\Mélytanulás\\Nagyházi\\Twitter_GNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Krisztián\\Documents\\Homework\\Mélytanulás\\Nagyházi\\Twitter_GNN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Krisztián\\Documents\\Homework\\Mélytanulás\\Nagyházi\\Twitter_GNN\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[1;32mc:\\Users\\Krisztián\\Documents\\Homework\\Mélytanulás\\Nagyházi\\Twitter_GNN\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:99\u001b[0m, in \u001b[0;36mgcn_norm\u001b[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[1;32m---> 99\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    104\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Krisztián\\Documents\\Homework\\Mélytanulás\\Nagyházi\\Twitter_GNN\\lib\\site-packages\\torch_geometric\\utils\\loop.py:650\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[0;32m    648\u001b[0m     is_undirected \u001b[38;5;241m=\u001b[39m edge_index\u001b[38;5;241m.\u001b[39mis_undirected\n\u001b[1;32m--> 650\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[0;32m    653\u001b[0m     edge_index\u001b[38;5;241m.\u001b[39m_is_undirected \u001b[38;5;241m=\u001b[39m is_undirected\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "lr, emb_dim, hidden = 0.001, 20, 256\n",
    "model = GCN(emb_size, emb_dim, hidden, n2v).to(DEVICE)\n",
    "\n",
    "train_model(model=model, train_loader=train_loader, val_loader=val_loader, optimizer=\"Adam\", lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced GNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Something that actually works\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Twitter_GNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
